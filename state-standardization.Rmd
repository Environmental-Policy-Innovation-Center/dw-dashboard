---
title: "SRF PPL & IUP Standardization"
author: "Walker Grimshaw & Phil Cork"
date: "2022-12-20"
output: pdf_document
geometry: margin=2.54cm
editor_options: 
  chunk_output_type: console
---

# Settings & Imports

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

options(scipen=999999999)

library(tidyverse)
library(data.table)
library(janitor)
library(aws.s3)
library(googledrive)
library(googlesheets4)

```


# Import Clean State Data

```{r}
# Alabama
source("year1/AL/code/clean-AL.R")
al_clean <- clean_al()

# Alaska

# Arkansas
source("year1/AR/code/clean-AR.R")
ar_clean <- clean_ar()

# Arizona

# California
source("year1/CA/code/clean-CA.R")
ca_clean <- clean_ca()

# Colorado
source("year1/CO/code/clean-CO.R")
co_clean <- clean_co()

# Connecticut
source("year1/CT/code/clean-CT.R")
ct_clean <- clean_ct()

# Delaware
source("year1/DE/code/clean-DE.R")
de_clean <- clean_de()

# District of Columbia
source("year1/DC/code/clean-DC.R")
dc_clean <- clean_dc()

# Florida
source("year1/FL/code/clean-FL.R")
fl_clean <- clean_fl()

# Georgia
source("year1/GA/code/clean-GA.R")
ga_clean <- clean_ga()

# Hawaii
source("year1/HI/code/clean-HI.R")
hi_clean <- clean_hi()

# Idaho
source("year1/ID/code/clean-ID.R")
id_clean <- clean_id()

# Illinois
source("year1/IL/code/clean-IL.R")
il_clean <- clean_il()

# Indiana
source("year1/IN/code/clean-IN.R")
in_clean <- clean_in()

# Iowa

# Kansas
source("year1/KS/code/clean-KS.R")
ks_clean <- clean_ks()

# Kentucky
source("year1/KY/code/clean-KY.R")
ky_clean <- clean_ky()

# Louisiana
source("year1/LA/code/clean-LA.R")
la_clean <- clean_la()

# Maine
source("year1/ME/code/clean-ME.R")
me_clean <- clean_me()

# Maryland
source("year1/MD/code/clean-MD.R")
md_clean <- clean_md()

# Massachusetts
source("year1/MA/code/clean-MA.R")
ma_clean <- clean_ma()

# Michigan
source("year1/MI/code/clean-MI.R")
mi_clean <- clean_mi()

# Minnesota
source("year1/MN/code/clean-MN.R")
mn_clean <- clean_mn()

# Mississippi
source("year1/MS/code/clean-MS.R")
ms_clean <- clean_ms()

# Missouri
source("year1/MO/code/clean-MO.R")
mo_clean <- clean_mo()

# Montana
source("year1/MT/code/clean-MT.R")
mt_clean <- clean_mt()

# Nebraska
source("year1/NE/code/clean-NE.R")
ne_clean <- clean_ne()

# New Hampshire
source("year1/NH/code/clean-NH.R")
nh_clean  <- clean_nh()

# New Jersey
source("year1/NJ/code/clean-NJ.R")
nj_clean <- clean_nj()

# New Mexico
source("year1/NM/code/clean-NM.R")
nm_clean <- clean_nm()

# Nevada
source("year1/NV/code/clean-NV.R")
nv_clean <- clean_nv()

# New York
source("year1/NY/code/clean-NY.R")
ny_clean <- clean_ny()

# North Carolina
source("year1/NC/code/clean-NC.R")
nc_clean <- clean_nc()

# North Dakota
source("year1/ND/code/clean-ND.R")
nd_clean <- clean_nd()

# Ohio
source("year1/OH/code/clean-OH.R")
oh_clean <- clean_oh()

# Oklahoma
source("year1/OK/code/clean-OK.R")
ok_clean <- clean_ok()

# Oregon

# Pennsylvania
source("year1/PA/code/clean-PA.R")
pa_clean <- clean_pa()

# Rhode Island
source("year1/RI/code/clean-RI.R")
ri_clean <- clean_ri()

# South Carolina
source("year1/SC/code/clean-SC.R")
sc_clean <- clean_sc()

# South Dakota
source("year1/SD/code/clean-SD.R")
sd_clean <- clean_sd()

# Tennessee (NS)

# Texas
source("year1/TX/code/clean-TX.R")
tx_clean <- clean_tx()

# Utah
source("year1/UT/code/clean-UT.R")
ut_clean <- clean_ut()

# Virginia

# Vermont
source("year1/VT/code/clean-VT.R")
vt_clean <- clean_vt()

# Washington
source("year1/WA/code/clean-WA.R")
wa_clean <- clean_wa()

# West Virginia
source("year1/WV/code/clean-WV.R")
wv_clean <- clean_wv()

# Wisconsin
source("year1/WI/code/clean-WI.R")
wi_clean <- clean_wi()
  
```


# Post-Process

# Combine & Format States

```{r}
# create a list of all objects and boolean for whether each object is a dataframe
dfs <- sapply(.GlobalEnv, is.data.frame) 
# for each TRUE, add the dataframe rows to a single data.frame
combined_clean <- do.call(bind_rows, mget(names(dfs)[dfs]))


# Cleaning for table on web, currently leaves in Applicant projects for 1.1 release.
projects_clean_web <- combined_clean %>%
                          mutate(across(everything(), as.character),
                                 ) %>%
                          select(state, cities_served, borrower,
                                 pwsid, project_name, project_description,
                                 project_type, funding_amount, principal_forgiveness_amount, project_cost, requested_amount,
                                 population, disadvantaged, state_rank, state_score, funding_status, category) %>% 
                          rename(State = state,
                                Borrower = borrower, 
                                `City Served` = cities_served, 
                                `Project Description` = project_description,
                                `Project Type` = project_type,
                                `State Rank` = state_rank,
                                `State Score` = state_score,
                                `Project Cost` = project_cost,
                                `Requested Amount` = requested_amount,
                                `Funding Amount` = funding_amount, 
                                `Principal Forgiveness` = principal_forgiveness_amount,
                                `Meets State Disadvantaged Criteria` = disadvantaged,
                                 Population = population,
                                 PWSID = pwsid, 
                                `Project Name` = project_name,
                                `Funding Status` = funding_status,
                                `Category` = category)

```


# Add Data for Dashboard

```{r}

# SABs Data ## 
sabs_raw <- read_csv(get_object(object = "service_area_boundaries/sabs_app/Dev_Data_v1.csv", bucket = "tech-team-data"))

sabs_cleaned <- sabs_raw %>%
  mutate(Population = pop_tier1 + pop_tier2 + pop_tier3,
         Systems = num_sys_tier1 + num_sys_tier2 + num_sys_tier3) %>%
  rename(State = State_Name) %>%
  select(State, Population, Systems)

# Additional Data 
# TODO: Put this on AWS # 
# Sourced from Attachment A DWISNA Allotments and Pipe Estimates: https://www.epa.gov/system/files/documents/2023-04/Final_FY23%20DWSRF%20Allotment%20Memo%20and%20Attachments_April%202023.pdf
# Sourced from the 20-year need (page 9 + 10): https://www.epa.gov/system/files/documents/2023-04/Final_DWINSA%20Public%20Factsheet%204.4.23.pdf

URL <- "https://docs.google.com/spreadsheets/d/1hznoLfB8zMzs3jKfLjs-uy9R68mcFsYMAUg1gKXC17Y/edit#gid=0"

state_needs_estimates <- read_sheet(URL, sheet = "AdditionalData")

# Summary Data For Application # 
funded_states <- projects_clean_web %>%
  filter(`Funding Status` == "Funded") %>%
  mutate(Count = 1,
         DAC = as.numeric(ifelse(`Meets State Disadvantaged Criteria` == "Yes","1","0")),
         `Principal Forgiveness` = as.numeric(`Principal Forgiveness`),
         `Funding Amount` = as.numeric(`Funding Amount`)) %>%
  select(State, `Funding Amount`, `Principal Forgiveness`, DAC, Count) %>%
  group_by(State) %>%
  summarize_if(is.numeric,sum,na.rm = TRUE) %>%
  left_join(sabs_cleaned) %>%
  left_join(state_needs_estimates, by = c("State"= "State")) %>%
  mutate(FundPer100k = (`Funding Amount` / Population))

# separate states that only have applicant data to ensure they don't fall through the cracks while aggregating
only_applicant_states <- projects_clean_web %>%
  filter(Category == "2") %>%
  mutate(Count = 1,
         DAC = as.numeric(ifelse(`Meets State Disadvantaged Criteria` == "Yes","1","0")),
         `Principal Forgiveness` = as.numeric(`Principal Forgiveness`),
         `Funding Amount` = as.numeric(`Funding Amount`)) %>%
  select(State, `Funding Amount`, `Principal Forgiveness`, DAC, Count) %>%
  group_by(State) %>%
  summarize_if(is.numeric,sum,na.rm = TRUE) %>%
  left_join(sabs_cleaned) %>%
  left_join(state_needs_estimates, by = c("State"= "State")) %>%
  mutate(FundPer100k = (`Funding Amount` / Population))

state_category <- projects_clean_web %>%
  select(State, Category) %>%
  distinct()

# recombine states
all_states <- rbind(funded_states, only_applicant_states) %>%
  left_join(state_category)
                            
```


# Write to AWS

```{r}

## To put in an AWS bucket, you need these credentials
# Contact gabe@policyinnovation.org for questions/access
# !!! NOTE !!! NEVER WRITE CREDENTIALS IN CODE, ENTER IN CONSOLE AS ENVIRONMENT VARIABLES !!!! NOTE !!!! ### 

 # Sys.setenv("AWS_ACCESS_KEY_ID" = "",
 #             "AWS_SECRET_ACCESS_KEY" = "",
 #             "AWS_DEFAULT_REGION" = "us-east-1")


## Write State-Level Data ## 

# Writing to temp 
write.csv(all_states, file.path(tempdir(), "dw-dashboard-data_v1-1.csv"), row.names = FALSE)

#Putting in Bucket
##TODO: For all-y1-states PR, change this to remove the v1-1 suffix and change app to read the updated file
put_object(
  file = file.path(tempdir(), "dw-dashboard-data_v1-1.csv"),
  object = "apps/dw-dashboard/dw-dashboard-data_v1-1.csv",
  bucket = "water-team-data",
  acl = "public-read"
)

## Write Project-Level Data ###


# Writing to temp 
write.csv(projects_clean_web, file.path(tempdir(), "projects_clean_web.csv"), row.names=FALSE)

#Putting in Bucket
put_object(
  file = file.path(tempdir(), "projects_clean_web.csv"),
  object = "clean_data/srf_project_priority_lists/web_ppl_combined_clean.csv",
  bucket = "water-team-data",
  acl = "public-read"
)

# TODO: Push v[n] to srf_dashboard_data_public and update meta-data about when it was last updated

```
