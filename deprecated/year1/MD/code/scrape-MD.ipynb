{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import camelot.io as camelot\n",
    "import ghostscript\n",
    "import sys\n",
    "\n",
    " # adding folders up to system path to access functions\n",
    "sys.path.insert(0, '../../../')\n",
    "from driveFolderHandler import downloadTempDriveFolder, deleteTempDriveFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1_uGOMbnd44RCXV_LVCLaryuzHtD5ENCm MD_IUP_2023.pdf\n",
      "Processing file 1oEdooB90yJKh2N6pv96Dc4Bv94a3ruOx MD_PPL_2023.pdf\n",
      "Building directory structure completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder list completed\n",
      "Building directory structure\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1_uGOMbnd44RCXV_LVCLaryuzHtD5ENCm\n",
      "To: /Users/pcork/epic/dw-dashboard/year1/MD/temp-docs/MD_IUP_2023.pdf\n",
      "100%|██████████| 595k/595k [00:00<00:00, 6.72MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1oEdooB90yJKh2N6pv96Dc4Bv94a3ruOx\n",
      "To: /Users/pcork/epic/dw-dashboard/year1/MD/temp-docs/MD_PPL_2023.pdf\n",
      "100%|██████████| 738k/738k [00:00<00:00, 6.31MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files stored in ../temp-docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Download completed\n"
     ]
    }
   ],
   "source": [
    "path = \"../temp-docs\"\n",
    "downloadTempDriveFolder(folderID='1o_DxZ5MoX6OmOsNG88_iuXY-WILYiY_p',\n",
    "                        path = path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maryland\n",
    "\n",
    "### Comprehensive PPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "md_comp = camelot.read_pdf(path+\"/MD_PPL_2023.pdf\", \n",
    "                           pages='1-9', flavor='lattice')\n",
    "print(len(md_comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list to append into\n",
    "list_of_dfs = []\n",
    "\n",
    "for i in range(len(md_comp)):\n",
    "    # read in each page\n",
    "    md = md_comp[i].df.iloc[1:,].copy()\n",
    "\n",
    "    ## split the 0 column (Rank/Points) by line breaks\n",
    "    # regex looks for a number greedily, then any amount of whtie space, then another number greedily\n",
    "    md[['Rank', 'Points']] = md[0].str.extract(r'(\\d+)\\s*(\\d+)')\n",
    "\n",
    "\n",
    "    ##split the 1 column (Project Title / Number / Population) by the opening parantheses before the pwsid\n",
    "    md[['ProjectTitle', 'PWSID.Pop.ProjectNumber']] = md[1].str.split(\"\\n\\(MD\", expand=True)\n",
    "\n",
    "    # split PWSID from Population and ProjectNumber by the other parentheses\n",
    "    md[['PWSID', 'Pop.ProjectNumber']] = md[\"PWSID.Pop.ProjectNumber\"].str.split(\"\\)\\n\", expand=True)\n",
    "    # add MD back to the PWSID after using it to split earlier columns to avoid issues with multiple splits\n",
    "    md['PWSID'] = \"MD\" + md['PWSID']\n",
    "\n",
    "    # remove population pretense\n",
    "    md['Pop.ProjectNumber'] = md['Pop.ProjectNumber'].str.replace(\"Ben.Pop=\\n\", \"\")\n",
    "\n",
    "    # split population and project number\n",
    "    md[['Population', 'ProjectNumber']] = md['Pop.ProjectNumber'].str.split(\"\\n\", expand=True)\n",
    "\n",
    "    #replace line breaks with spaces in ProjectTitle\n",
    "    md['ProjectTitle'] = md['ProjectTitle'].str.replace(\"\\n\", \" \") \n",
    "\n",
    "\n",
    "    ## column 2 only needs line breaks replace with spaces\n",
    "    md['ProjectDescription'] = md[2].str.replace(\"\\n\", \" \") \n",
    "\n",
    "\n",
    "    ## column 3 (Applicant Name / County) split by system size and characters around it\n",
    "    md[[\"Name.Borrower\", \"Size.County\"]] = md[3].str.split(\"\\nSystem Size =\\n\", expand=True, n=2)\n",
    "\n",
    "    # split by breaks only once because names are only one line but borrower can be two, replace remaining line breaks with space\n",
    "    md[[\"Name\", \"Borrower\"]] = md['Name.Borrower'].str.split(\"\\n\", n=1, expand=True)\n",
    "    md['Borrower'] = md['Borrower'].str.replace(\"\\n\", \" \")\n",
    "\n",
    "    # split by line break\n",
    "    md[['Size', 'County']] = md['Size.County'].str.split(\"\\n\", expand=True)\n",
    "\n",
    "\n",
    "    ## column 4 only needs to be split by line breaks, but this data is not currently used in the dashboard\n",
    "    # md[[\"LegDistrict\", \"CongDistrict\"]] = md[4].str.split(\"\\n\", n=1, expand=True)\n",
    "\n",
    "\n",
    "    ## column 5 needs to have Disadvantaged extracted from it, the rest is not currently used in the dashboard\n",
    "    md['Disadvantaged'] = np.where(md[5].str.contains(\"DISADV.\"), \"Yes\", \"No\")\n",
    "\n",
    "    ## column 6 can be ignored because we currently use no dates in the dashboard\n",
    "\n",
    "    ## column 7 splits by line break between Total Cost and a variable we won't use for dashboard purposes\n",
    "    md[['TotalCost', 'Details']] = md[7].str.split(\"\\n\", n=1, expand=True)\n",
    "\n",
    "\n",
    "    ## column 8 - in each row, the numbers are the same, so just keep the first, similar to column 7\n",
    "    md[['RequestedFunding', 'LoanDetails']] = md[8].str.split(\"\\n\", n=1, expand=True)\n",
    "\n",
    "    # drop in-process columns\n",
    "    md.drop(columns=[0,1,2,3,4,5,6,7,8,'Size', 'Name.Borrower', 'Size.County', 'Details','LoanDetails', \n",
    "            'PWSID.Pop.ProjectNumber', 'Pop.ProjectNumber'], inplace=True)\n",
    "\n",
    "    # append to list    \n",
    "    list_of_dfs.append(md)\n",
    "    \n",
    "# concat with common column names    \n",
    "md_output = pd.concat(list_of_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_output.reset_index(drop=True, inplace=True)\n",
    "# drop total rows\n",
    "md_output = md_output.iloc[:-2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_output.to_csv(\"../data/year1/csv/20-Maryland_ComprehensivePPL.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted folder and all files within ../temp-docs\n"
     ]
    }
   ],
   "source": [
    "deleteTempDriveFolder(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
